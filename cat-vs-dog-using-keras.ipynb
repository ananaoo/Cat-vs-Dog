{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:15px;\n           background-color:#314f90;\n           font-size:200%;\n           font-family:Newtime-Roman;\n           font-style: Arial;\n           letter-spacing:0.10px\">\n\n<p style=\"font-size:35px; color:white; text-align:center\"> Introduction</p>\n</div>","metadata":{}},{"cell_type":"markdown","source":"The goal of this work is to build a machine learning model that will determine from a photo whether a cat or a dog is depicted. Based on the specifics, the task is a binary classification.  \nThe architecture of the model will be a convolutional neural network, because it has significant advantages for working with images:\n- Fewer trainable parameters, since the same set of weights is used for all neurons in the feature map - which is called the convolution core  \n- A convolutional neural network receives not a vector, but a matrix or tensor at its input (unlike a fully connected neural network, or standard machine learning algorithms)\n\nIn order to speed up the training of the model, we will use the GPU. An important point is the problem of retraining in CNN, so at the design stage it is necessary to take this fact into account in advance.  \nThe CNN model will be built using Keras  \nIn the process of processing, we will make all images of a unique size of 200x200x3 (since the model must accept objects of standard sizes).  \nSince there is no class imbalance (0, 1) in the dataset, Accuracy is a completely objective metric, so we will choose it as the metric","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:15px;\n           background-color:#314f90;\n           font-size:200%;\n           font-family:Newtime-Roman;\n           font-style: Arial;\">\n\n<p style=\"font-size:35px; color:white; text-align:center\"> Table of content</p>\n</div>","metadata":{}},{"cell_type":"markdown","source":"### [**1) Library import**](#title-one)\n\n### [**2) Getting data**](#title-two)\n\n### [**3) EDA**](#title-three)\n    \n### [**4) Data preprocessing**](#title-four) \n\n### [**5) Creating a CNN model**](#title-five)\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"title-one\"></a>\n<div style=\"color:white;\n           display:fill;\n           border-radius:15px;\n           background-color:#314f90;\n           font-size:200%;\n           font-family:Newtime-Roman;\n           font-style: Arial;\">\n\n<p style=\"font-size:35px; color:white; text-align:center\">1) Library import</p>\n</div>","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport cv2\nimport sklearn\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, BatchNormalization, Dropout, Input\nfrom tensorflow.keras.layers import Rescaling\nfrom tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom\nfrom keras import callbacks\nfrom keras.layers import Dense, Flatten, BatchNormalization, GlobalAveragePooling2D, Dropout, Input\nfrom keras import Model\nfrom keras.layers import  Conv2D, MaxPool2D, add\nfrom keras.preprocessing import image\nimport random\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'","metadata":{"execution":{"iopub.status.busy":"2022-12-11T17:26:17.420738Z","iopub.execute_input":"2022-12-11T17:26:17.421708Z","iopub.status.idle":"2022-12-11T17:26:26.146561Z","shell.execute_reply.started":"2022-12-11T17:26:17.421616Z","shell.execute_reply":"2022-12-11T17:26:26.145322Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"title-three\"></a>\n<div style=\"color:white;\n           display:fill;\n           border-radius:15px;\n           background-color:#314f90;\n           font-size:200%;\n           font-family:Newtime-Roman;\n           font-style: Arial;\">\n\n<p style=\"font-size:35px; color:white; text-align:center\">2) Getting data</p>\n</div>","metadata":{}},{"cell_type":"markdown","source":"A few words about the dataset:  \nIn the dataset, the data is already divided into train and test. For valid in the learning process, we will take part of the data from train.  \nCurrently, the data is in the form of images, CNN does not know how to process images in pure form, it is necessary to submit a tensor to the input, so we will deal with the representation of images in the form of a tensor.   \nLet's create data generators for train, valid, test based on the dataset:","metadata":{}},{"cell_type":"code","source":"training_path = '../input/cat-and-dog/training_set/training_set/'\ntest_path = '../input/cat-and-dog/test_set/test_set/'\nIMAGE_SIZE = (150, 150)\nBATCH_SIZE = 150","metadata":{"execution":{"iopub.status.busy":"2022-12-10T23:05:06.623196Z","iopub.execute_input":"2022-12-10T23:05:06.623903Z","iopub.status.idle":"2022-12-10T23:05:06.632356Z","shell.execute_reply.started":"2022-12-10T23:05:06.623869Z","shell.execute_reply":"2022-12-10T23:05:06.631413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = keras.utils.image_dataset_from_directory(\n    directory=\"../input/cat-and-dog/training_set/training_set\",\n    batch_size=BATCH_SIZE,\n    image_size=IMAGE_SIZE,\n    shuffle=True,\n    seed=42,\n    validation_split=0.15,\n    subset='training'\n)\n\ntest_ds = tf.keras.utils.image_dataset_from_directory(\n    directory=\"../input/cat-and-dog/test_set/test_set\",\n    batch_size=BATCH_SIZE,\n    image_size=IMAGE_SIZE,\n    shuffle=True,\n    seed=42\n)\n\nvalid_ds = tf.keras.utils.image_dataset_from_directory(\n    directory=\"../input/cat-and-dog/training_set/training_set\",\n    batch_size=BATCH_SIZE,\n    image_size=IMAGE_SIZE,\n    shuffle=True,\n    seed=42,\n    validation_split=0.15,\n    subset='validation'\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-10T23:05:06.634119Z","iopub.execute_input":"2022-12-10T23:05:06.634481Z","iopub.status.idle":"2022-12-10T23:05:08.645653Z","shell.execute_reply.started":"2022-12-10T23:05:06.634448Z","shell.execute_reply":"2022-12-10T23:05:08.644354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# in order to access the generator elements, you can use the .take() method. For example:\n# for batch, labels in train_ds.take(1):\n#     print(batch, labels)    ","metadata":{"execution":{"iopub.status.busy":"2022-12-10T23:05:08.652382Z","iopub.execute_input":"2022-12-10T23:05:08.652857Z","iopub.status.idle":"2022-12-10T23:05:08.661834Z","shell.execute_reply.started":"2022-12-10T23:05:08.652817Z","shell.execute_reply":"2022-12-10T23:05:08.660541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"title-four\"></a>\n<div style=\"color:white;\n           display:fill;\n           border-radius:15px;\n           background-color:#314f90;\n           font-size:200%;\n           font-family:Newtime-Roman;\n           font-style: Arial;\">\n\n<p style=\"font-size:35px; color:white; text-align:center\">3) EDA</p>\n</div>","metadata":{}},{"cell_type":"markdown","source":"Let's see what this data is:","metadata":{}},{"cell_type":"code","source":"cnt_imgs = 16  # we take 8 images for each class\ncat_path = training_path + '/cats'\ndog_path = training_path + '/dogs'\ncat_imgs = os.listdir(cat_path)[:cnt_imgs]\ndog_imgs = os.listdir(dog_path)[:cnt_imgs]","metadata":{"execution":{"iopub.status.busy":"2022-12-10T23:05:08.667527Z","iopub.execute_input":"2022-12-10T23:05:08.668173Z","iopub.status.idle":"2022-12-10T23:05:08.68239Z","shell.execute_reply.started":"2022-12-10T23:05:08.668138Z","shell.execute_reply":"2022-12-10T23:05:08.681165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"counter = 0\ncat_imgs_path = [cat_path + '/' + i for i in cat_imgs]\ndog_imgs_path = [dog_path + '/' + j for j in dog_imgs]\nall_imgs = cat_imgs_path + dog_imgs_path\nrandom.shuffle(all_imgs)\n\nplt.figure(figsize=(28, 10))\nfor img_path in all_imgs:\n    plt.subplot(4, 8, counter + 1)\n    img = cv2.imread(img_path)\n    img = cv2.resize(img, IMAGE_SIZE)\n    label = img_path[len(training_path) + 1: img_path.rfind('/')]\n    plt.imshow(img)\n    plt.title(label)\n    plt.axis('off')\n    counter += 1","metadata":{"execution":{"iopub.status.busy":"2022-12-10T23:05:08.687001Z","iopub.execute_input":"2022-12-10T23:05:08.689685Z","iopub.status.idle":"2022-12-10T23:05:10.506293Z","shell.execute_reply.started":"2022-12-10T23:05:08.689652Z","shell.execute_reply":"2022-12-10T23:05:10.503864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's also see if there is an imbalance of classes:","metadata":{}},{"cell_type":"code","source":"def check_cnt_label(label: str) -> int:\n    \"\"\"A function that should determine the number of objects of this\n    class in the specified directories\"\"\"\n    cnt_object = 0\n    paths = [training_path, test_path]\n    for path in paths:\n        path += '/' + label\n        cnt_object += len(os.listdir(path))\n    return cnt_object\n\nCNT_CAT = check_cnt_label('cats')\nCNT_DOG = check_cnt_label('dogs')","metadata":{"execution":{"iopub.status.busy":"2022-12-10T23:05:10.507612Z","iopub.execute_input":"2022-12-10T23:05:10.508637Z","iopub.status.idle":"2022-12-10T23:05:10.519685Z","shell.execute_reply.started":"2022-12-10T23:05:10.508599Z","shell.execute_reply":"2022-12-10T23:05:10.518837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Bar(\n    x=['Cats', 'Dogs'],\n    y=[CNT_CAT, CNT_DOG],\n    width=[0.4, 0.4]))\n\nfig.update_layout(title='Classes and their number in the dataset', title_x=0.5)","metadata":{"execution":{"iopub.status.busy":"2022-12-10T23:05:10.521038Z","iopub.execute_input":"2022-12-10T23:05:10.522046Z","iopub.status.idle":"2022-12-10T23:05:10.535948Z","shell.execute_reply.started":"2022-12-10T23:05:10.522014Z","shell.execute_reply":"2022-12-10T23:05:10.535138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"What can we see from this graph:\n- There is no class imbalance, so the Accuracy metric is objective\n- There are 10,000 objects on train, valid, test in total","metadata":{}},{"cell_type":"markdown","source":"<a id=\"title-five\"></a>\n<div style=\"color:white;\n           display:fill;\n           border-radius:15px;\n           background-color:#314f90;\n           font-size:200%;\n           font-family:Newtime-Roman;\n           font-style: Arial;\">\n\n<p style=\"font-size:35px; color:white; text-align:center\">4) Data preprocessing </p>\n</div>","metadata":{}},{"cell_type":"markdown","source":"It is necessary to scale the data, because the neural network must accept numbers in the range from 0 to 1 as input. Changing the image size to the standard value (200, 200) was carried out already at the stage of creating generators. Data augmentation is not provided for this work","metadata":{}},{"cell_type":"code","source":"rescale = Rescaling(scale=1.0 / 255)\n\ntrain_ds = train_ds.map(lambda image, label: (rescale(image), label))\n\nvalid_ds  = valid_ds.map(lambda image, label: (rescale(image), label))\n\ntest_ds = test_ds.map(lambda image, label: (rescale(image), label))","metadata":{"execution":{"iopub.status.busy":"2022-12-10T23:05:10.537212Z","iopub.execute_input":"2022-12-10T23:05:10.538062Z","iopub.status.idle":"2022-12-10T23:05:10.568778Z","shell.execute_reply.started":"2022-12-10T23:05:10.538018Z","shell.execute_reply":"2022-12-10T23:05:10.567988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"title-six\"></a>\n<div style=\"color:white;\n           display:fill;\n           border-radius:15px;\n           background-color:#314f90;\n           font-size:200%;\n           font-family:Newtime-Roman;\n           font-style: Arial;\">\n\n<p style=\"font-size:35px; color:white; text-align:center\">5) Creating a CNN model</p>\n</div>","metadata":{}},{"cell_type":"markdown","source":"To reduce overfitting, we will use the following methods:\n- Change the number of epochs  \n- Use callback  \n- Change the complexity of the model  \n- Use Dropout layers in the model","metadata":{}},{"cell_type":"code","source":"# We will also set the number of epochs:\nEPOCHS = 35","metadata":{"execution":{"iopub.status.busy":"2022-12-10T23:05:10.572261Z","iopub.execute_input":"2022-12-10T23:05:10.57252Z","iopub.status.idle":"2022-12-10T23:05:10.577897Z","shell.execute_reply.started":"2022-12-10T23:05:10.572496Z","shell.execute_reply":"2022-12-10T23:05:10.576854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CALLBACKS = [\n    callbacks.EarlyStopping(monitor='loss', min_delta=0.01, patience=7, verbose=1),  \n    callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, min_delta=0.01, min_lr=1e-10, patience=2, verbose=1, mode='auto')\n]","metadata":{"execution":{"iopub.status.busy":"2022-12-10T23:05:10.579497Z","iopub.execute_input":"2022-12-10T23:05:10.579905Z","iopub.status.idle":"2022-12-10T23:05:10.58643Z","shell.execute_reply.started":"2022-12-10T23:05:10.579821Z","shell.execute_reply":"2022-12-10T23:05:10.585268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = Input(shape=(IMAGE_SIZE + (3,)))\n\nx = Conv2D(32, (3, 3), activation='elu')(inputs)\nx = BatchNormalization()(x)\nx = Conv2D(64, (3, 3), activation='elu')(x)\nblock_1_output = MaxPool2D(pool_size=(3, 3))(x)\n\nx = Conv2D(64, (3, 3), activation='elu', padding='same')(block_1_output)\nx = BatchNormalization()(x)\nx = Conv2D(64, (3, 3), activation='elu', padding='same')(x)\nblock_2_output = add([x, block_1_output])\n\nx = Conv2D(64, (3, 3), activation='elu', padding='same')(block_2_output)\nx = BatchNormalization()(x)\nx = Conv2D(64, (3, 3), activation='elu', padding='same')(x)\nblock_3_output = add([x, block_2_output])\n\nx = Conv2D(128, (3, 3), activation='elu')(block_3_output)\nx = MaxPool2D(pool_size=(2, 2))(x)\nx = GlobalAveragePooling2D()(x)\nx = Dense(256, activation='elu')(x)\noutput = Dense(1, activation='sigmoid')(x)","metadata":{"execution":{"iopub.status.busy":"2022-12-10T23:13:32.297843Z","iopub.execute_input":"2022-12-10T23:13:32.298248Z","iopub.status.idle":"2022-12-10T23:13:32.439652Z","shell.execute_reply.started":"2022-12-10T23:13:32.298215Z","shell.execute_reply":"2022-12-10T23:13:32.436857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model(inputs, output)","metadata":{"execution":{"iopub.status.busy":"2022-12-10T23:05:10.694493Z","iopub.status.idle":"2022-12-10T23:05:10.695061Z","shell.execute_reply.started":"2022-12-10T23:05:10.694811Z","shell.execute_reply":"2022-12-10T23:05:10.694834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(metrics=['Accuracy'], loss='binary_crossentropy', optimizer='Adam')","metadata":{"execution":{"iopub.status.busy":"2022-12-10T23:05:10.697153Z","iopub.status.idle":"2022-12-10T23:05:10.697624Z","shell.execute_reply.started":"2022-12-10T23:05:10.697382Z","shell.execute_reply":"2022-12-10T23:05:10.697403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_ds, epochs=EPOCHS, validation_data=valid_ds, callbacks=CALLBACKS)","metadata":{"execution":{"iopub.status.busy":"2022-12-10T23:05:10.699454Z","iopub.status.idle":"2022-12-10T23:05:10.699948Z","shell.execute_reply.started":"2022-12-10T23:05:10.699689Z","shell.execute_reply":"2022-12-10T23:05:10.699711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(24, 8))\nplt.title('Visualization of the model learning process', fontsize=14)\nplt.plot(np.arange(1, EPOCHS + 1), history.history['Accuracy'], label='The fraction of correct answers on the training set') \nplt.plot(np.arange(1, EPOCHS + 1), history.history['val_Accuracy'], label='The fraction of correct answers of the validation set')\nplt.xlabel('Epochs', fontsize=14)\nplt.ylabel('The fraction of correct answers', fontsize=14)\nplt.xticks(np.arange(1, EPOCHS + 1), fontsize=14)\nplt.yticks(fontsize=14)\nplt.xlim(1, 15)\nplt.grid()\nplt.legend(fontsize=14)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-10T23:05:10.701755Z","iopub.status.idle":"2022-12-10T23:05:10.702238Z","shell.execute_reply.started":"2022-12-10T23:05:10.701997Z","shell.execute_reply":"2022-12-10T23:05:10.702019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-12-10T23:05:10.704072Z","iopub.status.idle":"2022-12-10T23:05:10.704535Z","shell.execute_reply.started":"2022-12-10T23:05:10.704295Z","shell.execute_reply":"2022-12-10T23:05:10.704317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_result = model.evaluate(test_ds, verbose=0)[1]\ntrain_result = model.evaluate(train_ds, verbose=0)[1]\nprint(f'Metric on test: {test_result}')\nprint(f'Metric on train: {train_result}')","metadata":{"execution":{"iopub.status.busy":"2022-12-10T23:05:10.705936Z","iopub.status.idle":"2022-12-10T23:05:10.707025Z","shell.execute_reply.started":"2022-12-10T23:05:10.70675Z","shell.execute_reply":"2022-12-10T23:05:10.706773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"title-six\"></a>\n<div style=\"color:white;\n           display:fill;\n           border-radius:15px;\n           background-color:#314f90;\n           font-size:200%;\n           font-family:Newtime-Roman;\n           font-style: Arial;\">\n\n<p style=\"font-size:35px; color:white; text-align:center\">END</p>\n</div>","metadata":{}}]}